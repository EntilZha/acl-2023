---
title: Main Conference Keynotes
layout: single
permalink: /program/keynotes/
sidebar: 
    nav: program
toc: true
toc_sticky: true
toc_icon: "cog"
---

We are delighted to announce that the esteemed speakers listed below have graciously accepted our invitation to deliver keynote speeches at the main conference of ACL 2023:

<style>
p.title { font-weight: bold; font-size: 120%; }
</style>

<style>
p.time { font-style: italic; font-size: 90%; }
</style>

<style>
p.speaker-bio { font-style: italic; font-size: 80%; }
</style>

## Geoffrey Hinton

![Geoffrey Hinton](/assets/images/keynotes/geoffrey_hinton.jpg){: .align-center}

**<font size="5">Two Paths to Intelligence</font>**<br>
*Monday, July 10, 9:30 - 10:30 EDT*

I will briefly describe the forty year history of neural net language models with particular attention to whether they understand what they are saying. I will then discuss some of the main differences between digital and biological intelligences and speculate on how the brain could implement something like transformers. I will conclude by addressing the contentious issue of whether current multimodal LLMs have subjective experience.

Geoffrey Hinton received his PhD in Artificial Intelligence from Edinburgh in 1978.  After five years as a faculty member at Carnegie-Mellon he became a fellow of the Canadian Institute for Advanced Research and moved to the University of Toronto where he is now an emeritus professor. He is also the Chief Scientific Adviser at the Vector Institute.
{: .speaker-bio}

He was one of the researchers who introduced the backpropagation algorithm and the first to use backpropagation for learning word embeddings. His other contributions to neural network research include Boltzmann machines, distributed representations, time-delay neural nets, mixtures of experts, variational learning and deep learning.  His research group in Toronto made major breakthroughs in deep learning that revolutionized speech recognition and object classification.
{: .speaker-bio}

He is a fellow of the UK Royal Society and a foreign member of the US National Academy of Engineering, the US National Academy of Sciences and the American Academy of Arts and Sciences. His awards include the David E. Rumelhart prize, the IJCAI award for research excellence, the Killam prize for Engineering, the Royal Society Royal Medal, the NSERC Herzberg Gold Medal, the IEEE James Clerk Maxwell Gold medal, the NEC C&C award, the BBVA award, the Honda Prize and the Turing Award.
{: .speaker-bio}


## Alison Gopnik

![Alison Gopnik](/assets/images/keynotes/alison_gopnik.jpg){: .align-center}

**<font size="5">Large Language Models as Cultural Technologies: Imitation and Innovation in Children and Models</font>**<br>
*Wednesday, July 12, 14:00 - 15:00 EDT*

Its natural to ask whether large language models like LaMDA or GPT-3 are intelligent agents. But I argue that this is the wrong question. Intelligence and agency are the wrong categories for understanding them. Instead, these Al systems are what we might call cultural technologies, like writing, print, libraries, internet search engines or even language itself. They are new techniques for passing on information from one group of people to another. Cultural technologies arent like intelligent humans, but they are essential for human intelligence. Many animals can transmit some information from one individual or one generation to another, but no animal does it as much as we do or accumulates as much information over time, . New technologies that make cultural transmission easier and more effective have been among the greatest engines of human progress, but they have also led to negative as well as positive social consequences. Moreover, while cultural technologies allow transmission of existing information cultural evolution, which is central to human success, also depends on innovation, exploration and causal learning. Comparing LLM's responses in prompts based on developmental psychology experiments to the responses of children may provide insight into which capacities can be learned through language and cultural transmission, and which require innovation and exploration in the physical world. I will present results from several studies making such comparisons.

Alison Gopnik is a professor of psychology and affiliate professor of philosophy at the University of California at Berkeley, and a member of the Berkeley AI Research Group. She received her BA from McGill University and her PhD. from Oxford University. She is a leader in the study of cognitive science and of children's learning and development and was one of the founders of the field of "theory of mind", an originator of the "theory of cognitive development", and the first to apply Bayesian probabilistic models to children's learning. She has received both the APS Lifetime Achievement Cattell and
William James Awards, the Bradford Washburn Award for Science Communication, and the SRCD Lifetime Achievement Award for Basic Science in Child Development. She is an elected member of the Society of Experimental Psychologists and the American Academy of Arts and Sciences and a Cognitive Science Society, American Association for the Advancement of Science, and Guggenheim Fellow. She was 2022-23 President of the Association for Psychological Science.
{: .speaker-bio}

She is the author or coauthor of over 140 journal articles and several books including "Words, thoughts and theories" MIT Press, 1997, and the bestselling and critically acclaimed popular books "The Scientist in the Crib" William Morrow, 1999, "The Philosophical Baby; What children's minds tell us about love, truth and the meaning of life" 2009, and "The Gardener and the Carpenter" 2016, Farrar, Strauss and Giroux, the latter two won the Cognitive Development Society Best Book Prize in 2009 and 2016. Since 2013 she has written the Mind and Matter column for the Wall Street Journal and
she has also written widely about cognitive science and psychology for The New York Times, The Economist, The Atlantic, The New Yorker, Scientific American, The Times Literary Supplement, The New York Review of Books, New Scientist and Slate, among others. Her TED talk on her work has been viewed more than 5.2 million times. She has frequently appeared on TV, radio and podcasts including "The Charlie Rose Show", "The Colbert Report", "Radio Lab" and "The Ezra Klein Show". She lives in Berkeley with her husband Alvy Ray Smith and has three children and five grandchildren.
{: .speaker-bio}